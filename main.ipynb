{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "November 2023\n",
    "\n",
    "@author: Askil Folger√∏\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using v2 for augmentation by instructions of the api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies Data Loader, train, valid, test without augmentation\n",
    "from NeuralNetworks import *\n",
    "from NeuralFunctions import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Data Loader, train, valid, test without augmentation\n",
    "train_data_path = './catdog_data/train/'\n",
    "validation_data_path = './catdog_data/validation/'\n",
    "test_data_path = './catdog_data/test/'\n",
    "\n",
    "transform = v2.Compose([\n",
    "    v2.Resize((256, 256)),\n",
    "    v2.ToTensor(),\n",
    "])\n",
    "\n",
    "augmentation_text = f\"\"\"\n",
    "new model with the \n",
    "following augmentations:\n",
    "\n",
    "- none\n",
    "\"\"\"\n",
    "\n",
    "transform_ii = v2.Compose([\n",
    "    v2.Resize((256, 256)),\n",
    "    v2.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data        = datasets.ImageFolder(root=train_data_path     , transform=transform)\n",
    "validation_data   = datasets.ImageFolder(root=validation_data_path, transform=transform_ii)\n",
    "test_data         = datasets.ImageFolder(root=test_data_path      , transform=transform_ii)\n",
    "\n",
    "# train_loader      = DataLoader(train_data, batch_size      = 64, shuffle= True)\n",
    "# validation_loader = DataLoader(validation_data, batch_size = 64, shuffle= False)\n",
    "test_loader       = DataLoader(test_data, batch_size       = 64, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies, Data Loader, train, valid, test with augmentation\n",
    "\n",
    "from NeuralNetworks import *\n",
    "from NeuralFunctions import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_data_path = './catdog_data/train/'\n",
    "validation_data_path = './catdog_data/validation/'\n",
    "test_data_path = './catdog_data/test/'\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.Resize((256)),\n",
    "    v2.CenterCrop(256),\n",
    "    v2.RandomPerspective(distortion_scale=0.2, p=0.2, interpolation=3, fill=0),\n",
    "    v2.RandomHorizontalFlip(p=0.2),\n",
    "    v2.RandomRotation(degrees=25),\n",
    "    v2.RandomAdjustSharpness(sharpness_factor=3, p=0.2),\n",
    "    v2.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
    "    # v2.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0), p=0.2),\n",
    "    v2.RandomGrayscale(p=0.2),\n",
    "    v2.RandomAutocontrast(p=0.2),\n",
    "    v2.RandomAffine(degrees=25, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=15),\n",
    "    v2.ToTensor(),\n",
    "    # v2.RandomErasing(p=0.2, scale=(0.01, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),\n",
    "])\n",
    "\n",
    "\n",
    "augmentation_text = f\"\"\"\n",
    "new model with the \n",
    "following augmentations:\n",
    "\n",
    "- resize to 256x256\n",
    "- RandomPerspective\n",
    "- RandomHorizontalFlip\n",
    "- RandomRotation\n",
    "- RandomAdjustSharpness\n",
    "- ColorJitter\n",
    "- RandomGrayscale\n",
    "- RandomAutocontrast\n",
    "- RandomAffine\n",
    "- ToTensor\n",
    "\"\"\"\n",
    "\n",
    "transform_ii = v2.Compose([\n",
    "    v2.Resize((256)),\n",
    "    v2.CenterCrop(256),\n",
    "    v2.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data        = datasets.ImageFolder(root=train_data_path     , transform=transforms)\n",
    "validation_data   = datasets.ImageFolder(root=validation_data_path, transform=transform_ii)\n",
    "test_data         = datasets.ImageFolder(root=test_data_path      , transform=transform_ii)\n",
    "\n",
    "train_loader      = DataLoader(train_data, batch_size      = 64, shuffle= True)\n",
    "validation_loader = DataLoader(validation_data, batch_size = 64, shuffle= False)\n",
    "test_loader       = DataLoader(test_data, batch_size       = 64, shuffle= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrainingParams(\n",
    "    model =  FivConvOneDenseCNNnet(0, 16, 32, 64, 128, 256, True), \n",
    "    optimizer_string= 'nadam',\n",
    "    criterion = nn.BCELoss(),\n",
    "\n",
    "    # runtime params\n",
    "    batch_size = 32,\n",
    "    epochs_value = 25,\n",
    "\n",
    "    # optimizer params\n",
    "    use_scheduler = True,\n",
    "    scheduler_factor = 0.5,\n",
    "    learning_rate_value = 0.001,\n",
    "    momentum_value = None,\n",
    "    dampening= 0.004,\n",
    "    nesterov= None,\n",
    "    momentum_decay= None,\n",
    "    betas = (0.7, 0.999),\n",
    "    amsgrad = None,\n",
    "    eps = 1e-10, \n",
    "\n",
    "    #regularization params\n",
    "    dropout_value = 0,\n",
    "    regularization = None,\n",
    "    weight_decay = None,\n",
    "\n",
    "    # info\n",
    "    train_data = train_data,\n",
    "    train_loader = None,\n",
    "    validation_data = validation_data,\n",
    "    validation_loader = None,\n",
    "    test_data = None,\n",
    "    test_loader = test_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1  \tTrain Loss: 0.7130 \tTest Loss: 0.7657 \tTest Accu: 0.61 \tcat: 474 \tdog: 126 \tprecision: 0.75, 0.57 \trecall: 0.32, 0.90\n",
      "Epoch:  2  \tTrain Loss: 0.5856 \tTest Loss: 0.9225 \tTest Accu: 0.62 \tcat:  97 \tdog: 503 \tprecision: 0.57, 0.87 \trecall: 0.96, 0.28\n",
      "Epoch:  3  \tTrain Loss: 0.5059 \tTest Loss: 0.5555 \tTest Accu: 0.72 \tcat: 327 \tdog: 273 \tprecision: 0.75, 0.71 \trecall: 0.68, 0.77\n",
      "Epoch:  4  \tTrain Loss: 0.4095 \tTest Loss: 0.9897 \tTest Accu: 0.65 \tcat: 494 \tdog: 106 \tprecision: 0.92, 0.59 \trecall: 0.33, 0.97\n",
      "Epoch:  5  \tTrain Loss: 0.3406 \tTest Loss: 1.2572 \tTest Accu: 0.59 \tcat: 105 \tdog: 495 \tprecision: 0.55, 0.75 \trecall: 0.91, 0.26\n",
      "Epoch:  6  \tTrain Loss: 0.3227 \tTest Loss: 1.3035 \tTest Accu: 0.61 \tcat: 507 \tdog:  93 \tprecision: 0.86, 0.57 \trecall: 0.27, 0.96\n",
      "Epoch:  7  \tTrain Loss: 0.2022 \tTest Loss: 0.7052 \tTest Accu: 0.75 \tcat: 380 \tdog: 220 \tprecision: 0.84, 0.69 \trecall: 0.61, 0.88\n",
      "Epoch:  8  \tTrain Loss: 0.1225 \tTest Loss: 0.6865 \tTest Accu: 0.75 \tcat: 355 \tdog: 245 \tprecision: 0.80, 0.71 \trecall: 0.66, 0.84\n",
      "Epoch:  9  \tTrain Loss: 0.0648 \tTest Loss: 0.8905 \tTest Accu: 0.70 \tcat: 208 \tdog: 392 \tprecision: 0.66, 0.79 \trecall: 0.86, 0.55\n",
      "Epoch: 10  \tTrain Loss: 0.0408 \tTest Loss: 0.6620 \tTest Accu: 0.78 \tcat: 295 \tdog: 305 \tprecision: 0.78, 0.79 \trecall: 0.79, 0.77\n",
      "Epoch: 11  \tTrain Loss: 0.0127 \tTest Loss: 0.6650 \tTest Accu: 0.78 \tcat: 284 \tdog: 316 \tprecision: 0.77, 0.80 \trecall: 0.81, 0.76\n",
      "Epoch: 12  \tTrain Loss: 0.0047 \tTest Loss: 0.7010 \tTest Accu: 0.79 \tcat: 328 \tdog: 272 \tprecision: 0.82, 0.77 \trecall: 0.74, 0.84\n",
      "Epoch: 13  \tTrain Loss: 0.0029 \tTest Loss: 0.6950 \tTest Accu: 0.79 \tcat: 324 \tdog: 276 \tprecision: 0.82, 0.77 \trecall: 0.75, 0.83\n",
      "Epoch: 14  \tTrain Loss: 0.0021 \tTest Loss: 0.7261 \tTest Accu: 0.79 \tcat: 333 \tdog: 267 \tprecision: 0.82, 0.76 \trecall: 0.73, 0.84\n",
      "Epoch: 15  \tTrain Loss: 0.0014 \tTest Loss: 0.7196 \tTest Accu: 0.80 \tcat: 323 \tdog: 277 \tprecision: 0.82, 0.78 \trecall: 0.76, 0.84\n",
      "Epoch: 16  \tTrain Loss: 0.0013 \tTest Loss: 0.7317 \tTest Accu: 0.79 \tcat: 319 \tdog: 281 \tprecision: 0.81, 0.77 \trecall: 0.76, 0.82\n",
      "Epoch: 17  \tTrain Loss: 0.0010 \tTest Loss: 0.7414 \tTest Accu: 0.80 \tcat: 323 \tdog: 277 \tprecision: 0.82, 0.77 \trecall: 0.76, 0.83\n",
      "Epoch: 18  \tTrain Loss: 0.0008 \tTest Loss: 0.7449 \tTest Accu: 0.80 \tcat: 327 \tdog: 273 \tprecision: 0.83, 0.78 \trecall: 0.76, 0.85\n",
      "Epoch: 19  \tTrain Loss: 0.0007 \tTest Loss: 0.7712 \tTest Accu: 0.80 \tcat: 321 \tdog: 279 \tprecision: 0.82, 0.78 \trecall: 0.76, 0.83\n",
      "Epoch: 20  \tTrain Loss: 0.0007 \tTest Loss: 0.7764 \tTest Accu: 0.80 \tcat: 330 \tdog: 270 \tprecision: 0.83, 0.77 \trecall: 0.75, 0.85\n",
      "Epoch: 21  \tTrain Loss: 0.0006 \tTest Loss: 0.8988 \tTest Accu: 0.80 \tcat: 327 \tdog: 273 \tprecision: 0.83, 0.78 \trecall: 0.76, 0.85\n",
      "Epoch: 22  \tTrain Loss: 0.0005 \tTest Loss: 0.9047 \tTest Accu: 0.81 \tcat: 317 \tdog: 283 \tprecision: 0.83, 0.79 \trecall: 0.78, 0.84\n",
      "Epoch: 23  \tTrain Loss: 0.0004 \tTest Loss: 0.9112 \tTest Accu: 0.81 \tcat: 319 \tdog: 281 \tprecision: 0.83, 0.79 \trecall: 0.77, 0.84\n",
      "Epoch: 24  \tTrain Loss: 0.0004 \tTest Loss: 0.9165 \tTest Accu: 0.81 \tcat: 329 \tdog: 271 \tprecision: 0.84, 0.78 \trecall: 0.76, 0.85\n",
      "Epoch: 25  \tTrain Loss: 0.0003 \tTest Loss: 0.9287 \tTest Accu: 0.81 \tcat: 325 \tdog: 275 \tprecision: 0.83, 0.78 \trecall: 0.76, 0.85\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    cnn_training_test_loop(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
