{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "November 2023\n",
    "\n",
    "@author: Askil Folger√∏\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using v2 for augmentation by instructions of the api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies Data Loader, train, valid, test without augmentation\n",
    "from NeuralNetworks import *\n",
    "from NeuralFunctions import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Data Loader, train, valid, test without augmentation\n",
    "train_data_path = './catdog_data/train/'\n",
    "validation_data_path = './catdog_data/validation/'\n",
    "test_data_path = './catdog_data/test/'\n",
    "\n",
    "transform = v2.Compose([\n",
    "    v2.Resize((256, 256)),\n",
    "    v2.ToTensor(),\n",
    "])\n",
    "\n",
    "augmentation_text = f\"\"\"\n",
    "new model with the \n",
    "following augmentations:\n",
    "\n",
    "- none\n",
    "\"\"\"\n",
    "\n",
    "transform_ii = v2.Compose([\n",
    "    v2.Resize((256, 256)),\n",
    "    v2.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data        = datasets.ImageFolder(root=train_data_path     , transform=transform)\n",
    "validation_data   = datasets.ImageFolder(root=validation_data_path, transform=transform_ii)\n",
    "test_data         = datasets.ImageFolder(root=test_data_path      , transform=transform_ii)\n",
    "\n",
    "# train_loader      = DataLoader(train_data, batch_size      = 64, shuffle= True)\n",
    "# validation_loader = DataLoader(validation_data, batch_size = 64, shuffle= False)\n",
    "test_loader       = DataLoader(test_data, batch_size       = 64, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies, Data Loader, train, valid, test with augmentation\n",
    "\n",
    "from NeuralNetworks import *\n",
    "from NeuralFunctions import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_data_path = './catdog_data/train/'\n",
    "validation_data_path = './catdog_data/validation/'\n",
    "test_data_path = './catdog_data/test/'\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.Resize((256)),\n",
    "    v2.CenterCrop(256),\n",
    "    v2.RandomPerspective(distortion_scale=0.2, p=0.2, interpolation=3, fill=0),\n",
    "    v2.RandomHorizontalFlip(p=0.2),\n",
    "    v2.RandomRotation(degrees=25),\n",
    "    v2.RandomAdjustSharpness(sharpness_factor=3, p=0.2),\n",
    "    v2.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
    "    # v2.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0), p=0.2),\n",
    "    v2.RandomGrayscale(p=0.2),\n",
    "    v2.RandomAutocontrast(p=0.2),\n",
    "    v2.RandomAffine(degrees=25, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=15),\n",
    "    v2.ToTensor(),\n",
    "    # v2.RandomErasing(p=0.2, scale=(0.01, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),\n",
    "])\n",
    "\n",
    "\n",
    "augmentation_text = f\"\"\"\n",
    "new model with the \n",
    "following augmentations:\n",
    "\n",
    "- resize to 256x256\n",
    "- RandomPerspective\n",
    "- RandomHorizontalFlip\n",
    "- RandomRotation\n",
    "- RandomAdjustSharpness\n",
    "- ColorJitter\n",
    "- RandomGrayscale\n",
    "- RandomAutocontrast\n",
    "- RandomAffine\n",
    "- ToTensor\n",
    "\"\"\"\n",
    "\n",
    "transform_ii = v2.Compose([\n",
    "    v2.Resize((256)),\n",
    "    v2.CenterCrop(256),\n",
    "    v2.ToTensor(),\n",
    "])\n",
    "\n",
    "train_data        = datasets.ImageFolder(root=train_data_path     , transform=transforms)\n",
    "validation_data   = datasets.ImageFolder(root=validation_data_path, transform=transform_ii)\n",
    "test_data         = datasets.ImageFolder(root=test_data_path      , transform=transform_ii)\n",
    "\n",
    "train_loader      = DataLoader(train_data, batch_size      = 64, shuffle= True)\n",
    "validation_loader = DataLoader(validation_data, batch_size = 64, shuffle= False)\n",
    "test_loader       = DataLoader(test_data, batch_size       = 64, shuffle= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrainingParams(\n",
    "    model =  FivConvOneDenseCNNnet(0, 16, 32, 64, 128, 256, True), \n",
    "    optimizer_string= 'nadam',\n",
    "    criterion = nn.BCELoss(),\n",
    "\n",
    "    # runtime params\n",
    "    batch_size = 32,\n",
    "    epochs_value = 25,\n",
    "\n",
    "    # optimizer params\n",
    "    use_scheduler = True,\n",
    "    scheduler_factor = 0.5,\n",
    "    learning_rate_value = 0.001,\n",
    "    momentum_value = None,\n",
    "    dampening= 0.004,\n",
    "    nesterov= None,\n",
    "    momentum_decay= None,\n",
    "    betas = (0.7, 0.999),\n",
    "    amsgrad = None,\n",
    "    eps = 1e-10, \n",
    "\n",
    "    #regularization params\n",
    "    dropout_value = 0,\n",
    "    regularization = None,\n",
    "    weight_decay = None,\n",
    "\n",
    "    # info\n",
    "    train_data = train_data,\n",
    "    train_loader = None,\n",
    "    validation_data = validation_data,\n",
    "    validation_loader = None,\n",
    "    test_data = None,\n",
    "    test_loader = test_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1  \tTrain Loss: 0.7167 \tTest Loss: 0.8166 \tTest Accu: 0.59 \tcat: 492 \tdog: 108 \tprecision: 0.76, 0.56 \trecall: 0.27, 0.91\n",
      "Epoch:  2  \tTrain Loss: 0.5874 \tTest Loss: 1.3872 \tTest Accu: 0.56 \tcat:  43 \tdog: 557 \tprecision: 0.53, 0.88 \trecall: 0.98, 0.13\n",
      "Epoch:  3  \tTrain Loss: 0.5048 \tTest Loss: 0.5689 \tTest Accu: 0.72 \tcat: 288 \tdog: 312 \tprecision: 0.71, 0.73 \trecall: 0.74, 0.70\n",
      "Epoch:  4  \tTrain Loss: 0.4156 \tTest Loss: 0.9475 \tTest Accu: 0.65 \tcat: 487 \tdog: 113 \tprecision: 0.90, 0.59 \trecall: 0.34, 0.96\n",
      "Epoch:  5  \tTrain Loss: 0.3412 \tTest Loss: 0.6706 \tTest Accu: 0.74 \tcat: 337 \tdog: 263 \tprecision: 0.78, 0.72 \trecall: 0.68, 0.81\n",
      "Epoch:  6  \tTrain Loss: 0.3120 \tTest Loss: 1.4645 \tTest Accu: 0.57 \tcat: 542 \tdog:  58 \tprecision: 0.88, 0.54 \trecall: 0.17, 0.98\n",
      "Epoch:  7  \tTrain Loss: 0.2025 \tTest Loss: 0.6346 \tTest Accu: 0.74 \tcat: 345 \tdog: 255 \tprecision: 0.79, 0.71 \trecall: 0.67, 0.82\n",
      "Epoch:  8  \tTrain Loss: 0.1141 \tTest Loss: 0.6619 \tTest Accu: 0.76 \tcat: 312 \tdog: 288 \tprecision: 0.77, 0.75 \trecall: 0.74, 0.78\n",
      "Epoch:  9  \tTrain Loss: 0.0602 \tTest Loss: 0.7514 \tTest Accu: 0.71 \tcat: 219 \tdog: 381 \tprecision: 0.67, 0.79 \trecall: 0.85, 0.58\n",
      "Epoch: 10  \tTrain Loss: 0.0313 \tTest Loss: 0.6476 \tTest Accu: 0.76 \tcat: 329 \tdog: 271 \tprecision: 0.78, 0.73 \trecall: 0.71, 0.80\n",
      "Epoch: 11  \tTrain Loss: 0.0108 \tTest Loss: 0.6408 \tTest Accu: 0.80 \tcat: 288 \tdog: 312 \tprecision: 0.79, 0.82 \trecall: 0.82, 0.78\n",
      "Epoch: 12  \tTrain Loss: 0.0040 \tTest Loss: 0.6795 \tTest Accu: 0.80 \tcat: 312 \tdog: 288 \tprecision: 0.81, 0.79 \trecall: 0.78, 0.82\n",
      "Epoch: 13  \tTrain Loss: 0.0025 \tTest Loss: 0.6974 \tTest Accu: 0.79 \tcat: 317 \tdog: 283 \tprecision: 0.81, 0.78 \trecall: 0.76, 0.82\n",
      "Epoch: 14  \tTrain Loss: 0.0017 \tTest Loss: 0.7153 \tTest Accu: 0.80 \tcat: 323 \tdog: 277 \tprecision: 0.82, 0.77 \trecall: 0.76, 0.83\n",
      "Epoch: 15  \tTrain Loss: 0.0013 \tTest Loss: 0.7122 \tTest Accu: 0.80 \tcat: 317 \tdog: 283 \tprecision: 0.81, 0.78 \trecall: 0.77, 0.82\n",
      "Epoch: 16  \tTrain Loss: 0.0011 \tTest Loss: 0.7309 \tTest Accu: 0.80 \tcat: 318 \tdog: 282 \tprecision: 0.82, 0.78 \trecall: 0.77, 0.83\n",
      "Epoch: 17  \tTrain Loss: 0.0009 \tTest Loss: 0.7394 \tTest Accu: 0.79 \tcat: 320 \tdog: 280 \tprecision: 0.81, 0.78 \trecall: 0.76, 0.83\n",
      "Epoch: 18  \tTrain Loss: 0.0008 \tTest Loss: 0.7498 \tTest Accu: 0.79 \tcat: 322 \tdog: 278 \tprecision: 0.82, 0.77 \trecall: 0.76, 0.83\n",
      "Epoch: 19  \tTrain Loss: 0.0007 \tTest Loss: 0.7636 \tTest Accu: 0.80 \tcat: 317 \tdog: 283 \tprecision: 0.81, 0.78 \trecall: 0.77, 0.82\n",
      "Epoch: 20  \tTrain Loss: 0.0006 \tTest Loss: 0.7708 \tTest Accu: 0.80 \tcat: 320 \tdog: 280 \tprecision: 0.82, 0.78 \trecall: 0.76, 0.83\n",
      "Epoch: 21  \tTrain Loss: 0.0005 \tTest Loss: 0.7639 \tTest Accu: 0.80 \tcat: 315 \tdog: 285 \tprecision: 0.81, 0.78 \trecall: 0.77, 0.82\n",
      "Epoch: 22  \tTrain Loss: 0.0005 \tTest Loss: 0.7684 \tTest Accu: 0.80 \tcat: 314 \tdog: 286 \tprecision: 0.81, 0.79 \trecall: 0.78, 0.82\n",
      "Epoch: 23  \tTrain Loss: 0.0004 \tTest Loss: 0.7906 \tTest Accu: 0.80 \tcat: 319 \tdog: 281 \tprecision: 0.81, 0.78 \trecall: 0.76, 0.83\n",
      "Epoch: 24  \tTrain Loss: 0.0004 \tTest Loss: 0.7881 \tTest Accu: 0.80 \tcat: 319 \tdog: 281 \tprecision: 0.81, 0.78 \trecall: 0.76, 0.83\n",
      "Epoch: 25  \tTrain Loss: 0.0003 \tTest Loss: 0.7997 \tTest Accu: 0.80 \tcat: 323 \tdog: 277 \tprecision: 0.82, 0.78 \trecall: 0.76, 0.84\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    cnn_training_test_loop(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
